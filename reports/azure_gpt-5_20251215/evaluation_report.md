# Ko-AgentBench 평가 보고서

## 실행 정보

- **평가 대상 모델**: azure/gpt-5
- **Judge 모델**: azure/gpt-4.1-mini
- **실행 날짜**: 20251215
- **평가 날짜**: 2025-12-16
- **총 태스크**: 106/106

## 📊 성능 요약

| Level | 태스크 수 | 평균 실행시간 | 평균 TPS | 평균 TTFT | 주요 지표 |
| --- | --- | --- | --- | --- | --- |
| **L1** | 11/11 | 7.7초 | 522 | 3.195초 | ToolAcc: 1.000, ArgAcc: 0.727 |
| **L2** | 30/30 | 12.4초 | 1022 | 4.944초 | SelectAcc: 1.000 |
| **L3** | 10/10 | 18.4초 | 2022 | 4.316초 | FSM: 0.600, PSM: 0.950 |
| **L4** | 10/10 | 27.3초 | 902 | 8.343초 | Coverage: 0.567 |
| **L5** | 20/20 | 22.3초 | 582 | 3.263초 | AdaptiveRoutingScore: 0.263, FallbackSR: 0.750 |
| **L6** | 15/15 | 41.8초 | 3521 | 6.452초 | EffScore: 0.441, ReuseRate: 0.000 |
| **L7** | 10/10 | 24.6초 | 2154 | 4.097초 | ContextRetention: 0.625 |

## 레벨별 성능

### Level 1: 단일 도구 호출

> 태스크 의도: 가장 기본적인 API 호출 능력 검증. 주어진 단일 도구를 정확한 파라미터로 호출할 수 있는지 확인
>
- 태스크 수: 11/11
- 평균 실행시간: 7.74초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 1.000 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **ArgAcc**: 0.727 - 인자 정확도. 도구 호출 시 전달한 인자들이 정답과 일치하는지 평가
- **CallEM**: 0.364 - 호출 완전 일치. 도구명과 모든 인자가 정답과 완벽하게 일치하는지 평가
- **EPR_CVR**: 1.000 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **RespOK**: 1.000 - 응답 파싱 성공. 도구 실행 결과를 성공적으로 파싱했는지 평가
- **ToolAcc**: 1.000 - 도구 선택 정확도. 정답 도구를 정확하게 선택했는지 평가
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

### Level 2: 도구 선택

> 태스크 의도: 여러 후보 도구 중 최적의 API를 선택하는 능력 검증. 주어진 도구 목록 중 가장 적합한 도구를 선택할 수 있는지 확인
>
- 태스크 수: 30/30
- 평균 실행시간: 12.42초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 0.967 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **EPR_CVR**: 1.000 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **SelectAcc**: 1.000 - 최종 선택 도구 정확도. 여러 후보군 중에서 최종적으로 올바른 도구를 선택했는지 평가
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

### Level 3: 멀티스텝 추론

> 태스크 의도: 여러 도구를 순차적으로 호출하고, 한 도구의 결과를 다음 도구의 입력으로 사용하여 복잡한 문제를 해결하는 능력 검증
>
- 태스크 수: 10/10
- 평균 실행시간: 18.44초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 1.000 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **EPR_CVR**: 0.988 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **FSM**: 0.600 - 정답 경로 완전 일치. 정해진 도구 호출 순서와 완벽하게 일치하는지 평가
- **PSM**: 0.950 - 정답 경로 부분 일치. 정답 경로의 일부를 얼마나 포함하고 있는지 평가
- **ProvAcc**: 0.150 - 데이터 출처 추적 정확도. 이전 단계의 출력값을 다음 단계의 입력값으로 정확히 연결했는지 평가
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율
- **ΔSteps_norm**: 0.500 - 최소 경로 대비 효율. 이론적인 최소 호출 횟수 대비 얼마나 효율적인 경로를 생성했는지 평가

### Level 4: 멀티소스 통합

> 태스크 의도: 여러 도구를 병렬적으로 호출하여 얻은 정보를 종합하고, 비교·분석하여 최종 결론을 도출하는 능력 검증
>
- 태스크 수: 10/10
- 평균 실행시간: 27.33초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 0.900 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **Coverage**: 0.567 - 소스 커버리지. 정보를 수집해야 하는 여러 소스를 누락 없이 호출했는지 평가
- **EPR_CVR**: 0.700 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **SourceEPR**: 0.567 - 소스별 유효 호출 비율. 병렬적으로 호출한 각 도구가 유효했는지 개별적으로 평가
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

### Level 5: 오류 처리

> 태스크 의도: 정보가 부족하거나 API 호출이 실패하는 등 예외적인 상황에 대처하는 능력 검증
>
- 태스크 수: 20/20
- 평균 실행시간: 22.27초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 0.800 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **AdaptiveRoutingScore**: 0.263 - 적응형 라우팅 점수. 주입된 도구 실패 이후 얼마나 신속하게 대체 경로로 전환하는지 평가
- **EPR_CVR**: 0.262 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **FallbackSR**: 0.750 - 대체 경로 성공률. 특정 도구 실패 시 다른 도구를 활용해 성공하는 비율
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

### Level 6: 컨텍스트 재사용

> 태스크 의도: 이전 대화에서 얻은 Tool 호출 결과를 기억하고, 불필요한 API 재호출 없이 효율적으로 답변하는 능력 검증
>
- 태스크 수: 15/15
- 평균 실행시간: 41.83초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 0.800 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **EPR_CVR**: 0.933 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **EffScore**: 0.441 - 효율 점수. 이론적 최소 호출 수와 재사용률을 종합하여 효율성을 점수화
- **RedundantCallRate**: 0.800 - 불필요 호출 비율. 정보를 이미 알고 있음에도 불필요하게 도구를 다시 호출하는 비율
- **ReuseRate**: 0.000 - 재사용 비율. 이전에 호출했던 결과를 재호출 없이 효율적으로 재사용하는 비율
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

### Level 7: 멀티턴 대화

> 태스크 의도: 여러 턴에 걸친 대화의 핵심 맥락을 기억하고, 이를 새로운 질문과 연결하여 정확한 Tool calling을 수행하는 능력 검증
>
- 태스크 수: 10/10
- 평균 실행시간: 24.57초

**메트릭 점수:**

- **RRR**: 1.000 - 응답 반환율. 모델이 기술적 오류(Exception, Timeout 등) 없이 최종 응답을 반환했는지 여부
- **SR**: 0.400 - 성공률. 주어진 태스크를 최종적으로 성공했는지 여부
- **ContextRetention**: 0.625 - 맥락 유지율. 여러 턴에 걸친 대화의 핵심 맥락을 답변에 올바르게 유지하는지 평가
- **EPR_CVR**: 1.000 - 유효 호출 비율. 생성한 도구 호출이 스키마상 유효하고 실행 가능한지 평가
- **RefRecall**: 0.600 - 장기 회상 비율. 대화 초반의 정보를 마지막 턴에서 다시 질문했을 때 정확히 기억해내는지 평가
- **pass@k**: 1.000 - 반복 안정성. 태스크를 k번 반복 수행했을 때 최소 한 번 이상 성공하는 비율

## 토큰 사용량 및 성능 지표

### 전체 요약

- **총 처리 토큰**: 4,042,809개
- **총 실행 시간**: 2234.02초
- **전체 평균 TPS**: 1809.66 tokens/sec
- **전체 평균 TTFT**: 4.8400초

### 레벨별 상세

| Level | 평균 토큰 수 | 입력 토큰 | 출력 토큰 | TPS | TTFT (평균) | TTFT (최소/최대) |
| --- | --- | --- | --- | --- | --- | --- |
| **L1** | 4035 | 3751 | 285 | 522 | 3.1948초 | 2.1111 / 5.6038 |
| **L2** | 12697 | 11972 | 725 | 1022 | 4.9437초 | 1.8267 / 9.2642 |
| **L3** | 37294 | 36201 | 1093 | 2022 | 4.3165초 | 3.4566 / 6.4760 |
| **L4** | 24660 | 23821 | 839 | 902 | 8.3426초 | 3.3601 / 12.6888 |
| **L5** | 12956 | 12088 | 869 | 582 | 3.2629초 | 1.7357 / 6.3737 |
| **L6** | 147302 | 145325 | 1977 | 3521 | 6.4517초 | 2.1464 / 13.3477 |
| **L7** | 52932 | 51888 | 1044 | 2154 | 4.0966초 | 1.3361 / 8.7866 |

